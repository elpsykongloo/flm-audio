<p align="left">
    ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="README.md">English</a>&nbsp 
</p>
<br><br>

# FLM-Audio

<p align="center">
        ğŸ¤— <a href="https://huggingface.co/CofeAI">Hugging Face</a>&nbsp&nbsp | &nbsp&nbspğŸ¤– <a href="https://modelscope.cn/organization/FLM">ModelScope</a>&nbsp&nbsp | &nbsp&nbsp ğŸ“‘ <a href="https://arxiv.org/abs/2509.02521">Paper</a> &nbsp&nbsp ï½œ &nbsp&nbspğŸ–¥ï¸ <a href="https://modelscope.cn/studios/FLM/FLM-Audio-Demo/summary">Demo</a>
</p>

FLM-Audio æ˜¯ä¸€ä¸ªåŸç”Ÿå…¨åŒå·¥è¯­éŸ³æ¨¡å‹ï¼Œå…¶æŠ€æœ¯æ¥æºäº [RoboEgo/FLM-Ego](https://arxiv.org/abs/2506.01934v1)ï¼Œä¸€ä¸ªåŸç”Ÿå…¨åŒå·¥ï¼ˆnative fullâ€‘duplexityï¼‰çš„å…¨æ¨¡æ€æ¨¡å‹ï¼ˆomnimodalï¼‰ã€‚FLM-Audioèƒ½å¤ŸåŒæ—¶å¬ã€è¯´å¹¶ç”Ÿæˆå†…éƒ¨ç‹¬ç™½ï¼Œä»¥ä½å»¶è¿Ÿåœ¨ä¸­è‹±æ–‡ä¸¤ç§è¯­è¨€ä¸­æä¾›åŒå‘å¯¹è¯ã€‚FLMâ€‘Audio å¯¹å™ªå£°ä¸ç”¨æˆ·æ‰“æ–­å…·æœ‰å¾ˆå¥½çš„é²æ£’æ€§ï¼Œå“åº”æ€§ä¸è‡ªç„¶åº¦å‡å¾—åˆ°äº†å¾ˆå¥½çš„ä¿è¯ã€‚

## æ¨¡å‹ä¿¡æ¯

- **æ”¯æŒè¯­è¨€ï¼š** æ±‰è¯­ã€è‹±è¯­

## æŠ€æœ¯æŠ¥å‘Š

åŠ¨æœºä¸ç»¼è¿°ï¼š [Toward Embodied AGI: A Review of Embodied AI and the Road Ahead](https://arxiv.org/abs/2505.14235)

FLM-Audio è®ºæ–‡ï¼š [FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training](https://arxiv.org/abs/2509.02521)

RoboEgo è®ºæ–‡ï¼š [RoboEgo System Card: An Omnimodal Model with Native Full Duplexity](https://arxiv.org/abs/2506.01934v1)

## åè§ã€é£é™©ä¸é™åˆ¶

å°½ç®¡ç»è¿‡å¤§é‡æ•°æ®æ¸…æ´—ï¼ŒFLMâ€‘Audio ä»å¯èƒ½äº§ç”Ÿä¸æœŸæœ›çš„å†…å®¹ï¼ˆä¾‹å¦‚å¸¦æœ‰åè§æˆ–å†’çŠ¯æ€§çš„è¯­è¨€ï¼‰ã€‚è¯·å‹¿å°†å¯èƒ½ä¸å®‰å…¨çš„è¾“å‡ºä¼ æ’­æˆ–ç”¨äºæœ‰å®³ç›®çš„ã€‚é¡¹ç›®ä½œè€…å¯¹è¯¯ç”¨æˆ–ç”±æ­¤äº§ç”Ÿçš„æœ‰å®³åæœä¸æ‰¿æ‹…è´£ä»»ã€‚

## å¿«é€Ÿå¼€å§‹

### æ¨èï¼šé€šè¿‡ Docker è¿è¡Œ Serverï¼ˆç”Ÿäº§/éƒ¨ç½²é¦–é€‰ï¼‰

æ¨èä½¿ç”¨å‘å¸ƒåœ¨ GitHub Container Registryï¼ˆghcr.ioï¼‰ä¸Š `cofe-ai` ç»„ç»‡çš„å®˜æ–¹ Docker é•œåƒæ¥è¿è¡ŒæœåŠ¡ï¼š

> `ghcr.io/cofe-ai/flm-audio`

é•œåƒå˜ä½“è¯´æ˜ï¼š

- `ghcr.io/cofe-ai/flm-audio:server-1.0.0-model-v202507` â€” **åŒ…å«å·²é¢„ä¸‹è½½çš„æ¨¡å‹**ï¼ˆé€‚ç”¨äºæ— æ³•è”ç½‘æˆ–éœ€è¦å¿«é€Ÿå¯åŠ¨çš„åœºæ™¯ï¼‰ã€‚
- `ghcr.io/cofe-ai/flm-audio:server-1.0.0` â€” **ä¸åŒ…å«æ¨¡å‹ï¼Œå®¹å™¨å¯åŠ¨åä¼šåœ¨è¿è¡Œæ—¶ä» Hugging Face ä¸‹è½½æ¨¡å‹**ï¼ˆéœ€è¦ç½‘ç»œï¼‰ã€‚

å¯åŠ¨ç¤ºä¾‹ï¼ˆæ¨èåœ¨æ— æ³•è”ç½‘æˆ–å¸Œæœ›é¿å…é¦–æ¬¡ä¸‹è½½å»¶è¿Ÿæ—¶ä½¿ç”¨å†…ç½®æ¨¡å‹é•œåƒï¼‰ï¼š

```bash
# ä½¿ç”¨å†…ç½®å·²ä¸‹è½½æ¨¡å‹çš„é•œåƒï¼ˆæ¨èï¼šæ— éœ€ä» Hugging Face ä¸‹è½½ï¼‰
docker run -dit --gpus '"device=1"' -p 8990:8990 --restart always --name flm-audio-server ghcr.io/cofe-ai/flm-audio:server-1.0.0-model-v202507

# æˆ–è€…ï¼šä½¿ç”¨ä¼šåœ¨è¿è¡Œæ—¶ä» Hugging Face è‡ªåŠ¨ä¸‹è½½æ¨¡å‹çš„é•œåƒï¼ˆéœ€è¦ç½‘ç»œï¼‰
docker run -dit --gpus '"device=1"' -p 8990:8990 --restart always --name flm-audio-server ghcr.io/cofe-ai/flm-audio:server-1.0.0
```

**è¯´æ˜**ï¼š
- `--gpus '"device=1"'`ï¼šç¤ºä¾‹ä¸­æŒ‡å®šä½¿ç”¨ç¼–å·ä¸º `1` çš„ GPUã€‚è¯·æ ¹æ®å®é™…æœºå™¨è°ƒæ•´ï¼ˆä¾‹å¦‚ `--gpus all` æˆ– `--gpus '"device=0,1"'`ï¼‰ã€‚
- ç«¯å£ `8990` æ˜¯ Server çš„é»˜è®¤ç«¯å£ï¼›å¦‚éœ€æ›´æ”¹å¯¹å¤–ç«¯å£ï¼Œå¯è°ƒæ•´ä¸º `-p ä¸»æœºç«¯å£:8990`ã€‚
- è‹¥é•œåƒæ‰˜ç®¡ä¸ºç§æœ‰ä»“åº“ï¼Œå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œ `docker login ghcr.io` å¹¶ä½¿ç”¨ GitHub Personal Access Tokenï¼ˆPATï¼‰è¿›è¡Œè®¤è¯ï¼Œå…·ä½“å–å†³äºä»“åº“è®¿é—®æƒé™ã€‚
- ä½¿ç”¨ä¸å¸¦é¢„ç½®æ¨¡å‹çš„é•œåƒï¼ˆ`server-1.0.0`ï¼‰æ—¶ï¼Œå®¹å™¨é¦–æ¬¡å¯åŠ¨ä¼šè”ç½‘ä¸‹è½½æ¨¡å‹ï¼Œä¸‹è½½æ—¶é—´å–å†³äºç½‘ç»œå’Œæ¨¡å‹å¤§å°ï¼›ä½¿ç”¨å¸¦é¢„ç½®æ¨¡å‹çš„é•œåƒåˆ™æ— éœ€ç½‘ç»œå³å¯å¯åŠ¨ã€‚

è¯·æ³¨æ„ï¼Œé¦–æ¬¡å¯åŠ¨å®¹å™¨çš„æ—¶å€™ï¼Œä¸ºäº†åŠ é€Ÿæ¨ç†ï¼Œæ¨¡å‹åŠ è½½åéœ€è¦ç¼–è¯‘ä¸€æ®µæ—¶é—´ï¼ˆçº¦2åˆ†é’Ÿï¼Œç”±æœåŠ¡å™¨æ€§èƒ½å†³å®šï¼‰ï¼Œå½“çœ‹åˆ°æ—¥å¿—ä¿¡æ¯åŒ…å«å¦‚ä¸‹å†…å®¹æ—¶ï¼Œè¡¨æ˜å·²ç»å®Œå…¨å¯åŠ¨æˆåŠŸï¼š
```
[Info] model loaded
[Info] warming up the model
[Info] Access the API directly at http://0.0.0.0:8990/api/chat
======== Running on http://0.0.0.0:8990 ========
(Press CTRL+C to quit)
```

### æœ¬åœ°å¯åŠ¨æœåŠ¡ï¼ˆå¯é€‰ï¼‰

è‹¥ç”¨äºæœ¬åœ°å¼€å‘æˆ–è°ƒè¯•ï¼Œå¯ç›´æ¥ä»¥ Python æ–¹å¼è¿è¡Œï¼š

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements-server.txt
# å¯åŠ¨ server
python -m flmaudio.server --port 8990
```

> æ³¨æ„ï¼šæœ¬åœ°å¯åŠ¨åŒæ ·éœ€è¦æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼›è‹¥æœªæå‰ä¸‹è½½ï¼Œç¨‹åºå°†å°è¯•ä» Hugging Face è·å–å¯¹åº”æ¨¡å‹æƒé‡ã€‚


### å¯åŠ¨ Web UIï¼ˆè¿æ¥åˆ°å·²è¿è¡Œçš„ Serverï¼‰

```bash
# å¯åŠ¨ Web UIï¼ˆGradioï¼‰ï¼Œè¿æ¥åˆ°æœ¬åœ°æˆ–è¿œç¨‹ server
pip install -r requirements-clientgui.txt
python -m flmaudio.client_gradio --url http://localhost:8990
```

ç„¶åå°±å¯ä»¥åœ¨æµè§ˆå™¨æ‰“å¼€ http://localhost:50000 è¿›è¡Œä½“éªŒã€‚

### å¯åŠ¨ CLIï¼ˆè¿æ¥åˆ°å·²è¿è¡Œçš„ Serverï¼‰

```bash
# å¯åŠ¨ CLI å®¢æˆ·ç«¯
pip install -r requirements-clientcli.txt
python -m flmaudio.client --url http://localhost:8990
```

**è¯´æ˜**ï¼š
- æ— è®ºæ˜¯Web UI è¿˜æ˜¯ CLIæ–¹å¼ï¼Œå‡éœ€è¦å°† url æ›¿æ¢ä¸ºä½ çš„æœåŠ¡æ‰€åœ¨æœåŠ¡å™¨çš„ipå’Œç«¯å£ï¼Œè®°å¾—é˜²ç«å¢™æ”¾è¡Œï¼›
- ä½¿ç”¨ Web UI æ—¶ï¼Œç”±äºgradioå’Œç°ä»£æµè§ˆå™¨çš„å®‰å…¨æªæ–½ï¼Œå»ºè®®ä½ åœ¨è°ƒè¯•æ—¶å€™ï¼Œæ‰§è¡Œpythonå‘½ä»¤çš„æœºå™¨å’Œæµè§ˆå™¨åœ¨åŒä¸€å°æœºå™¨ä¸Šï¼Œè¿™æ ·å¯ä»¥åœ¨æµè§ˆå™¨ä¸Šä½¿ç”¨localhost

## æ¨èè¿è¡Œç¯å¢ƒ

- **æ“ä½œç³»ç»Ÿï¼š** Linuxï¼ˆæ¨èï¼‰ã€‚
- **GPUï¼š** NVIDIA GPUï¼Œ**å»ºè®®æ˜¾å­˜ä¸å°‘äº 20 GB**ï¼Œä»¥ä¿è¯å¤§æ¨¡å‹æ¨ç†çš„ç¨³å®šæ€§ä¸æ€§èƒ½ã€‚
- **è½¯ä»¶ï¼š** Dockerã€NVIDIA Container Toolkitï¼ˆç”¨äºå®¹å™¨å†… GPU æ”¯æŒï¼Œäº¦ç§° `nvidia-docker`ï¼‰ï¼Œä»¥åŠåŒ¹é…çš„ NVIDIA é©±åŠ¨ç¨‹åºã€‚
- **å­˜å‚¨ï¼š** ä¸ºæ¨¡å‹æ–‡ä»¶ä¸æ—¥å¿—é¢„ç•™å……è¶³ç£ç›˜ç©ºé—´ï¼ˆæ¨¡å‹æ–‡ä»¶é€šå¸¸éœ€è¦ 16GBï¼‰ã€‚
- **ç½‘ç»œï¼š** ä»…åœ¨ä½¿ç”¨ä¸å«æ¨¡å‹çš„é•œåƒæˆ–é€‰æ‹©åœ¨çº¿ä¸‹è½½æ¨¡å‹æ—¶éœ€è¦ï¼›ä½¿ç”¨åŒ…å«æ¨¡å‹çš„é•œåƒåˆ™æ— éœ€è”ç½‘å³å¯å¯åŠ¨ã€‚

## å¸¸è§é—®é¢˜ï¼ˆç®€è¦ï¼‰

- **æˆ‘åº”è¯¥é€‰æ‹©å“ªä¸ªé•œåƒï¼Ÿ**
  - å¦‚æœæœåŠ¡å™¨å¯ä»¥è®¿é—®äº’è”ç½‘ä¸”ä¸ä»‹æ„é¦–æ¬¡ä¸‹è½½ï¼šå¯ä½¿ç”¨ `server-1.0.0`ã€‚
  - å¦‚æœæœåŠ¡å™¨æ— æ³•è”ç½‘ï¼Œæˆ–å¸Œæœ›å¼€ç®±å³ç”¨ã€å¿«é€Ÿå¯åŠ¨ï¼šè¯·ä½¿ç”¨ `server-1.0.0-model-v202507`ï¼ˆå·²é¢„ç½®æ¨¡å‹ï¼‰ã€‚

- **å¦‚ä½•æŒ‡å®šä¸åŒçš„ GPUï¼Ÿ**
  - è°ƒæ•´ `--gpus` å‚æ•°ï¼Œä¾‹å¦‚ `--gpus '"device=0"'` æˆ– `--gpus all`ï¼ˆå…·ä½“æ”¯æŒå’Œè¯­æ³•å–å†³äºä¸»æœºä¸Šçš„ Docker ä¸ NVIDIA å®¹å™¨å·¥å…·é…ç½®ï¼‰ã€‚

## è‡´è°¢

æœ¬å·¥ä½œå—åˆ°æ–°ä¸€ä»£äººå·¥æ™ºèƒ½å›½å®¶ç§‘æŠ€é‡å¤§ä¸“é¡¹ (No. 2022ZD0116314)çš„æ”¯æŒï¼Œç‰¹æ­¤æ„Ÿè°¢ã€‚

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ï¼

```
@article{flm-audio,
  title={Flm-audio: Natural monologues improves native full-duplex chatbots via dual training},
  author={Yao, Yiqun and Li, Xiang and Jiang, Xin and Fang, Xuezhi and Yu, Naitong and Wenjia, Ma and Sun, Aixin and Wang, Yequan},
  journal={arXiv preprint arXiv:2509.02521},
  year={2025}
}
@article{embodied-agi,
  title={Toward embodied agi: A review of embodied ai and the road ahead},
  author={Wang, Yequan and Sun, Aixin},
  journal={arXiv preprint arXiv:2505.14235},
  year={2025}
}
@article{roboego,
  title={RoboEgo System Card: An Omnimodal Model with Native Full Duplexity},
  author={Yao, Yiqun and Li, Xiang and Jiang, Xin and Fang, Xuezhi and Yu, Naitong and Sun, Aixin and Wang, Yequan},
  journal={arXiv preprint arXiv:2506.01934},
  year={2025}
}
```

## ä½¿ç”¨åè®®

FLM-Audio ä½¿ç”¨ Apache License 2.0 æˆæƒï¼Œ`third_party/moshi` ç›®å½•ä¸‹çš„éƒ¨åˆ† Python ä»£ç é‡‡ç”¨ MIT è®¸å¯ï¼Œæœ¬æ¨¡å‹é»˜è®¤çš„éŸ³è‰²ç‰ˆæƒç”±åŸéŸ³è‰²æŒæœ‰äººä¿ç•™ã€‚æœ¬é¡¹ç›®ä»…ä¾›ç ”ç©¶ç”¨é€”ï¼Œé¡»éµå®ˆé€‚ç”¨æ³•å¾‹ï¼›å¦‚éœ€å•†ä¸šç”¨é€”ï¼Œè¯·è”ç³»æˆ‘ä»¬ã€‚
